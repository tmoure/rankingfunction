\relax 
\citation{cousot2012abstract}
\citation{10.1145/373243.360210}
\citation{urban2013abstract}
\citation{braverman2006termination}
\citation{turing1937on}
\citation{10.1007/978-3-540-27813-9_6}
\citation{colon2002practical}
\citation{10.1007/978-3-540-24622-0_20}
\citation{coloon2001synthesis}
\citation{yuan2019detecting}
\citation{li2019on}
\citation{10.1145/2629488}
\citation{bagnara2013eventual}
\citation{bradley2005polyranking}
\citation{ben2017multiphase}
\citation{bradley2005linear}
\citation{leike2014ranking}
\citation{li2016depth}
\citation{chen2007discovering}
\citation{cousot2005proving}
\citation{shen2013generating}
\citation{yuan2019ranking}
\citation{colon2002practical}
\citation{10.1007/978-3-540-24622-0_20}
\citation{coloon2001synthesis}
\citation{10.1145/2629488}
\citation{cousot2005proving}
\citation{shen2013generating}
\citation{chen2007discovering}
\citation{chen2007discovering}
\citation{yuan2019ranking}
\citation{fan2008liblinear:}
\citation{li2019synthesizing}
\citation{10.1007/978-3-540-78800-3_24}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}\protected@file@percent }
\newlabel{intro}{{1}{1}}
\citation{lecun2015deep}
\citation{hornik1989multilayer}
\citation{hornik1990universal}
\citation{leshno1993original}
\citation{li2019synthesizing}
\@writefile{toc}{\contentsline {section}{\numberline {2}Preliminaries}{2}\protected@file@percent }
\newlabel{Preliminaries}{{2}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Forms of loop programs}{2}\protected@file@percent }
\newlabel{Forms of loop programs}{{2.1}{2}}
\newlabel{equ:the form of loop}{{1}{2}}
\newlabel{exam1}{{1}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Ranking functions}{2}\protected@file@percent }
\newlabel{Ranking functions}{{2.2}{2}}
\newlabel{def}{{1}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Deep Neural Network}{2}\protected@file@percent }
\newlabel{Deep Neural Network}{{2.3}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {3}DNN-Based Synthesis of Ranking Functions}{3}\protected@file@percent }
\newlabel{DNN-Based Synthesis of Ranking Functions}{{3}{3}}
\newlabel{equ:Ux}{{3}{3}}
\newlabel{equ:Uu}{{4}{3}}
\newlabel{equ:u}{{5}{3}}
\newlabel{equ:x}{{6}{3}}
\newlabel{equ:x'}{{7}{3}}
\newlabel{equ:u'}{{8}{3}}
\newlabel{exam2}{{2}{3}}
\newlabel{thm1}{{1}{3}}
\newlabel{equ:thm1(1)}{{9}{3}}
\newlabel{equ:thm1(2)}{{10}{3}}
\newlabel{equ:thm1(3)}{{11}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Neural network structure\relax }}{4}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{neural structure}{{1}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Model Building}{4}\protected@file@percent }
\newlabel{Model Building}{{3.1}{4}}
\newlabel{equ:r(u)}{{12}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Sample points set}{4}\protected@file@percent }
\newlabel{Sample points set}{{3.2}{4}}
\newlabel{thm2}{{2}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Output layer structure\relax }}{5}\protected@file@percent }
\newlabel{outputlayer}{{2}{5}}
\newlabel{equ:y}{{13}{5}}
\newlabel{equ:decreasing condition}{{14}{5}}
\newlabel{thm3}{{3}{5}}
\newlabel{equ:LMT}{{15}{5}}
\newlabel{equ:|LMT|}{{16}{6}}
\newlabel{equ:LMT(1)}{{17}{6}}
\newlabel{equ:LMT(b)}{{18}{6}}
\newlabel{equ:LMT(b1)}{{19}{6}}
\newlabel{equ:LMT(2)}{{20}{6}}
\newlabel{equ:LMT(end)}{{21}{6}}
\newlabel{equ:contradicts}{{22}{6}}
\newlabel{equ:d}{{23}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Sampling process\relax }}{7}\protected@file@percent }
\newlabel{sample points}{{3}{7}}
\newlabel{algorithm1}{{1}{7}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}Construction of the sample points set $N_{sample}$ }{7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces  The particular set $s$\relax }}{8}\protected@file@percent }
\newlabel{the particular region}{{4}{8}}
\newlabel{thm4}{{4}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Train-set}{8}\protected@file@percent }
\newlabel{Train-set}{{3.3}{8}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}The inputs of neural work}{8}\protected@file@percent }
\newlabel{The inputs of neural work}{{3.3.1}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Coverage processes\relax }}{9}\protected@file@percent }
\newlabel{proof}{{5}{9}}
\newlabel{equ:N_sample and N_sample'}{{24}{9}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.2}The outputs of neural network}{9}\protected@file@percent }
\newlabel{The outputs of neural network}{{3.3.2}{9}}
\newlabel{Dtrain}{{\caption@xref {Dtrain}{ on input line 561}}{9}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces train-set $D_{train}$\relax }}{9}\protected@file@percent }
\newlabel{algorithm2}{{\caption@xref {algorithm2}{ on input line 579}}{10}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Construction of a train-set $D_{train}$\relax }}{10}\protected@file@percent }
\newlabel{exm3}{{3}{10}}
\newlabel{output of Dtrain}{{\caption@xref {output of Dtrain}{ on input line 620}}{10}}
\newlabel{tabel2}{{\caption@xref {tabel2}{ on input line 620}}{10}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces the output of $D_{train}$\relax }}{10}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}test-set}{10}\protected@file@percent }
\newlabel{test-set}{{3.4}{10}}
\newlabel{algorithm3}{{\caption@xref {algorithm3}{ on input line 650}}{11}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3}{\ignorespaces Synthesis of candidate ranking functions\relax }}{11}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Exact Verification}{11}\protected@file@percent }
\newlabel{Exact Verification}{{4}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Verification Process}{11}\protected@file@percent }
\newlabel{Verification Process}{{4.1}{11}}
\newlabel{prop}{{1}{11}}
\newlabel{equ:LMT(positive)}{{25}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Computation of $c$}{12}\protected@file@percent }
\newlabel{Computation}{{4.2}{12}}
\newlabel{equ:|r(u)-r(u')|}{{26}{12}}
\newlabel{equ:sigmoid(z)}{{27}{12}}
\newlabel{equ:|r(u)/u_k|}{{28}{12}}
\newlabel{equ:|r(u')/u_k|}{{29}{12}}
\citation{ben2017multiphase}
\newlabel{equ:method(u)}{{30}{13}}
\newlabel{equ:computing c}{{31}{13}}
\newlabel{exm4}{{4}{13}}
\newlabel{exm5}{{5}{14}}
\newlabel{algorithm4}{{\caption@xref {algorithm4}{ on input line 842}}{14}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {4}{\ignorespaces Synthesis of ranking functions\relax }}{14}\protected@file@percent }
\newlabel{exm6}{{6}{14}}
\newlabel{output of weights}{{\caption@xref {output of weights}{ on input line 868}}{14}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Output of weights\relax }}{14}\protected@file@percent }
\newlabel{equ:weight}{{32}{14}}
\citation{tensorflow2015-whitepaper}
\citation{yuan2019ranking}
\citation{ben2017multiphase}
\citation{yuan2019ranking}
\citation{ben2017multiphase}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces  Ranking function $R(x)$\relax }}{15}\protected@file@percent }
\newlabel{result1}{{6}{15}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Experiments}{15}\protected@file@percent }
\newlabel{Experiments}{{5}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Experimental results}{15}\protected@file@percent }
\newlabel{Experimental results}{{5.1}{15}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Loops for experiments.($\circ $: loops without transcendental terms; $\bullet $: loops with transcendental terms.)\relax }}{15}\protected@file@percent }
\newlabel{loops}{{4}{15}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces The tunable parameters and experimental results\relax }}{16}\protected@file@percent }
\newlabel{experiment results}{{5}{16}}
\citation{chen2007discovering}
\citation{yuan2019ranking}
\citation{ben2017multiphase}
\citation{chen2007discovering}
\citation{yuan2019ranking}
\citation{ben2017multiphase}
\citation{ben2017multiphase}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Method Comparsion}{17}\protected@file@percent }
\newlabel{Method Comparsion}{{5.2}{17}}
\newlabel{exm7}{{7}{18}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces \relax }}{18}\protected@file@percent }
\newlabel{neural structure for 3 neurons}{{7}{18}}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Output weights\relax }}{18}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces  Ranking function $R(x)$\relax }}{18}\protected@file@percent }
\newlabel{result2}{{8}{18}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusion}{18}\protected@file@percent }
\newlabel{Conclusion}{{6}{18}}
\bibstyle{spbasic}
\bibdata{mybibfile}
\bibcite{tensorflow2015-whitepaper}{{1}{2015}{{Abadi et~al.}}{{Abadi, Agarwal, Barham, Brevdo, Chen, Citro, Corrado, Davis, Dean, Devin, Ghemawat, Goodfellow, Harp, Irving, Isard, Jia, Jozefowicz, Kaiser, Kudlur, Levenberg, Man\'{e}, Monga, Moore, Murray, Olah, Schuster, Shlens, Steiner, Sutskever, Talwar, Tucker, Vanhoucke, Vasudevan, Vi\'{e}gas, Vinyals, Warden, Wattenberg, Wicke, Yu, and Zheng}}}
\bibcite{bagnara2013eventual}{{2}{2013}{{Bagnara and Mesnard}}{{}}}
\bibcite{10.1145/2629488}{{3}{2014}{{Ben-Amram and Genaim}}{{}}}
\bibcite{ben2017multiphase}{{4}{2017}{{Ben-Amram and Genaim}}{{}}}
\bibcite{bradley2005linear}{{5}{2005{}}{{Bradley et~al.}}{{Bradley, Manna, and Sipma}}}
\bibcite{bradley2005polyranking}{{6}{2005{}}{{Bradley et~al.}}{{Bradley, Manna, and Sipma}}}
\bibcite{braverman2006termination}{{7}{2006}{{Braverman}}{{}}}
\bibcite{chen2007discovering}{{8}{2007}{{Chen et~al.}}{{Chen, Xia, Yang, Zhan, and Zhou}}}
\bibcite{colon2002practical}{{9}{2002}{{Col{\'o}n and Sipma}}{{}}}
\bibcite{coloon2001synthesis}{{10}{2001}{{Col{\'o}on and Sipma}}{{}}}
\bibcite{cousot2005proving}{{11}{2005}{{Cousot}}{{}}}
\bibcite{cousot2012abstract}{{12}{2012}{{Cousot and Cousot}}{{}}}
\bibcite{fan2008liblinear:}{{13}{2008}{{Fan et~al.}}{{Fan, Chang, Hsieh, Wang, and Lin}}}
\bibcite{hornik1989multilayer}{{14}{1989}{{Hornik et~al.}}{{Hornik, Stinchcombe, White et~al.}}}
\bibcite{hornik1990universal}{{15}{1990}{{Hornik et~al.}}{{Hornik, Stinchcombe, and White}}}
\bibcite{lecun2015deep}{{16}{2015}{{Lecun et~al.}}{{Lecun, Bengio, and Hinton}}}
\bibcite{10.1145/373243.360210}{{17}{2001}{{Lee et~al.}}{{Lee, Jones, and Ben-Amram}}}
\bibcite{leike2014ranking}{{18}{2014}{{Leike and Heizmann}}{{}}}
\bibcite{leshno1993original}{{19}{1993}{{Leshno et~al.}}{{Leshno, Lin, Pinkus, and Schocken}}}
\bibcite{li2016depth}{{20}{2016}{{Li et~al.}}{{Li, Zhu, and Feng}}}
\bibcite{li2019synthesizing}{{21}{2019{}}{{Li et~al.}}{{Li, Sun, Li, Turrini, and Zhang}}}
\bibcite{li2019on}{{22}{2019{}}{{Li et~al.}}{{Li, Wu, and Feng}}}
\bibcite{10.1007/978-3-540-78800-3_24}{{23}{2008}{{de~Moura and Bj{\o }rner}}{{}}}
\bibcite{10.1007/978-3-540-24622-0_20}{{24}{2004}{{Podelski and Rybalchenko}}{{}}}
\bibcite{shen2013generating}{{25}{2013}{{Shen et~al.}}{{Shen, Wu, Yang, and Zeng}}}
\bibcite{10.1007/978-3-540-27813-9_6}{{26}{2004}{{Tiwari}}{{}}}
\bibcite{turing1937on}{{27}{1937}{{Turing}}{{}}}
\bibcite{urban2013abstract}{{28}{2013}{{Urban}}{{}}}
\bibcite{yuan2019ranking}{{29}{2019}{{Yuan and Li}}{{}}}
\bibcite{yuan2019detecting}{{30}{2019}{{Yuan et~al.}}{{Yuan, Li, and Shi}}}
